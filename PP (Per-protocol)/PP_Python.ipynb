{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30754262-b249-4911-94aa-eae5d82a67b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (873566349.py, line 653)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 653\u001b[0;36m\u001b[0m\n\u001b[0;31m    trial.plot_survival_difference()\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from lifelines import KaplanMeierFitter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "class TrialEmulation:\n",
    "    def __init__(self, data, estimand=\"Per-Protocol\"):\n",
    "        self.data = data.copy()\n",
    "        self.estimand = estimand\n",
    "        self.trial_data = None\n",
    "        self.msm_model = None\n",
    "        self.expanded_data = None\n",
    "        self.weight_models = None\n",
    "        self.censor_weights_specified = False\n",
    "        self.censor_weights_spec = None\n",
    "        self.switch_weights_specified = False\n",
    "        self.switch_weights_spec = None\n",
    "        self.expansion_specified = False\n",
    "        self.outcome_model_specified = False\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Display trial sequence information\"\"\"\n",
    "        output = []\n",
    "        output.append(\"\\nIPW for informative censoring:\")\n",
    "        if self.censor_weights_specified:\n",
    "            output.append(\" - Weights calculated\")\n",
    "        else:\n",
    "            output.append(\" - No weight model specified\")\n",
    "            \n",
    "        output.append(\"\\nIPW for treatment switch censoring:\")\n",
    "        if self.switch_weights_specified:\n",
    "            output.append(\" - Weights calculated\")\n",
    "        else:\n",
    "            output.append(\" - No weight model specified\")\n",
    "            \n",
    "        output.append(\"\\nSequence of Trials Data:\")\n",
    "        if hasattr(self, 'expanded_data') and self.expanded_data is not None:\n",
    "            output.append(\" - Expansion complete\")\n",
    "            self.expansion_specified = True\n",
    "        else:\n",
    "            output.append(\" - Use set_expansion_options() and expand_trials() to construct the sequence of trials dataset.\")\n",
    "\n",
    "        output.append(\"\\nOutcome model:\")\n",
    "        if hasattr(self, 'msm_model') and self.msm_model is not None:\n",
    "            output.append(\" - Model fitted\")\n",
    "            self.outcome_model_specified = True\n",
    "            output.append(f\" - Family: Binomial\")\n",
    "            output.append(f\" - Link: logit\")\n",
    "            output.append(f\" - Groups: {len(self.trial_data['id'].unique())}\")\n",
    "        else:\n",
    "            output.append(\" - Model not specified. Use set_outcome_model()\")\n",
    "            \n",
    "        return \"\\n\".join(output)\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Filter data according to per-protocol criteria\"\"\"\n",
    "        pp_data = self.data.copy()\n",
    "        pp_data = pp_data.sort_values(['id', 'period'])\n",
    "        \n",
    "        eligible_ids = pp_data[\n",
    "            (pp_data['period'] == 0) & \n",
    "            (pp_data['eligible'] == 1)\n",
    "        ]['id'].unique()\n",
    "        \n",
    "        pp_data = pp_data[pp_data['id'].isin(eligible_ids)]\n",
    "        \n",
    "        pp_data['prev_treatment'] = pp_data.groupby('id')['treatment'].shift(1)\n",
    "        pp_data['treatment_switch'] = (\n",
    "            (pp_data['treatment'] != pp_data['prev_treatment']) & \n",
    "            (pp_data['period'] > 0)\n",
    "        )\n",
    "        \n",
    "        pp_data['cumulative_switch'] = pp_data.groupby('id')['treatment_switch'].cumsum()\n",
    "        pp_data = pp_data[pp_data['cumulative_switch'] == 0]\n",
    "        pp_data = pp_data[pp_data['censored'] == 0]\n",
    "        \n",
    "        pp_data = pp_data.drop(['treatment_switch', 'cumulative_switch'], axis=1)\n",
    "        pp_data['prev_treatment'] = pp_data['prev_treatment'].fillna(pp_data['treatment'])\n",
    "        \n",
    "        self.trial_data = pp_data\n",
    "        return self\n",
    "\n",
    "    def show_weight_specs(self):\n",
    "        \"\"\"Display weight model specifications\"\"\"\n",
    "        output = []\n",
    "        \n",
    "        if self.censor_weights_spec is not None:\n",
    "            self.censor_weights_specified = True\n",
    "            output.append(\"\\n - Numerator formula: 1 - censored ~ \" + self.censor_weights_spec['numerator'])\n",
    "            output.append(\" - Denominator formula: 1 - censored ~ \" + self.censor_weights_spec['denominator'])\n",
    "            output.append(f\" - Numerator model is pooled across treatment arms: {self.censor_weights_spec['pool_models'] in ['numerator', 'both']}\")\n",
    "            output.append(\" - Model fitter type: te_stats_glm_logit\")\n",
    "            output.append(\" - Weight models not fitted. Use calculate_weights()\\n\")\n",
    "        else:\n",
    "            output.append(\" - No weight model specified\\n\")\n",
    "\n",
    "        if self.switch_weights_spec is not None:\n",
    "            self.switch_weights_specified = True\n",
    "            output.append(\"\\n - Numerator formula: treatment ~ \" + self.switch_weights_spec['numerator'])\n",
    "            output.append(\" - Denominator formula: treatment ~ \" + self.switch_weights_spec['denominator'])\n",
    "            output.append(\" - Model fitter type: te_stats_glm_logit\")\n",
    "            output.append(\" - Weight models not fitted. Use calculate_weights()\\n\")\n",
    "        else:\n",
    "            output.append(\" - No weight model specified\\n\")\n",
    "            \n",
    "        return \"\\n\".join(output)\n",
    "    \n",
    "    def calculate_weights(self):\n",
    "        \"\"\"Calculate IPW for censoring and treatment switching and store model statistics\"\"\"\n",
    "        self.weight_models = {\n",
    "            'censoring': {'numerator': None, 'denominator_0': None, 'denominator_1': None},\n",
    "            'switching': {'numerator_0': None, 'numerator_1': None, \n",
    "                         'denominator_0': None, 'denominator_1': None}\n",
    "        }\n",
    "        \n",
    "        if len(np.unique(self.trial_data['censored'])) == 1:\n",
    "            censor_weights = np.ones(len(self.trial_data))\n",
    "            self.weight_models['censoring']['numerator'] = {\n",
    "                'coefficients': np.array([0.0]),\n",
    "                'intercept': np.log(1e6),\n",
    "                'X': sm.add_constant(self.trial_data[['x2']]),\n",
    "                'y': np.ones(len(self.trial_data))\n",
    "            }\n",
    "        else:\n",
    "            censor_model_num = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "            X_num = sm.add_constant(self.trial_data[['x2']])\n",
    "            y = 1 - self.trial_data['censored']\n",
    "            \n",
    "            censor_model_num.fit(X_num, y)\n",
    "            num_probs = censor_model_num.predict_proba(X_num)[:, 1]\n",
    "            \n",
    "            self.weight_models['censoring']['numerator'] = {\n",
    "                'coefficients': censor_model_num.coef_[0],\n",
    "                'intercept': censor_model_num.intercept_[0],\n",
    "                'X': X_num,\n",
    "                'y': y\n",
    "            }\n",
    "            \n",
    "            censor_weights = np.ones(len(self.trial_data))\n",
    "            \n",
    "            for prev_treat in [0, 1]:\n",
    "                mask = self.trial_data['prev_treatment'] == prev_treat\n",
    "                if sum(mask) > 0:\n",
    "                    X_den = sm.add_constant(self.trial_data.loc[mask, ['x2', 'x1']])\n",
    "                    censor_model_den = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "                    censor_model_den.fit(X_den, y[mask])\n",
    "                    den_probs = censor_model_den.predict_proba(X_den)[:, 1]\n",
    "                    censor_weights[mask] = num_probs[mask] / (den_probs + 1e-8)\n",
    "                    \n",
    "                    self.weight_models['censoring'][f'denominator_{prev_treat}'] = {\n",
    "                        'coefficients': censor_model_den.coef_[0],\n",
    "                        'intercept': censor_model_den.intercept_[0],\n",
    "                        'X': X_den,\n",
    "                        'y': y[mask]\n",
    "                    }\n",
    "        \n",
    "        switch_weights = np.ones(len(self.trial_data))\n",
    "        \n",
    "        for prev_treat in [0, 1]:\n",
    "            mask = self.trial_data['prev_treatment'] == prev_treat\n",
    "            if sum(mask) > 0:\n",
    "                X_num = sm.add_constant(self.trial_data.loc[mask, ['age']])\n",
    "                y = self.trial_data.loc[mask, 'treatment']\n",
    "            \n",
    "                if len(np.unique(y)) > 1:\n",
    "                    switch_model_num = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "                    switch_model_num.fit(X_num, y)\n",
    "                    num_probs = switch_model_num.predict_proba(X_num)[:, 1]\n",
    "                    \n",
    "                    X_den = sm.add_constant(self.trial_data.loc[mask, ['age', 'x1', 'x3']])\n",
    "                    switch_model_den = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "                    switch_model_den.fit(X_den, y)\n",
    "                    den_probs = switch_model_den.predict_proba(X_den)[:, 1]\n",
    "                    \n",
    "                    probs_ratio = num_probs / (den_probs + 1e-8)\n",
    "                    switch_weights[mask] = probs_ratio\n",
    "                    \n",
    "                    self.weight_models['switching'][f'numerator_{prev_treat}'] = {\n",
    "                        'coefficients': switch_model_num.coef_[0],\n",
    "                        'intercept': switch_model_num.intercept_[0],\n",
    "                        'X': X_num,\n",
    "                        'y': y\n",
    "                    }\n",
    "                    \n",
    "                    self.weight_models['switching'][f'denominator_{prev_treat}'] = {\n",
    "                        'coefficients': switch_model_den.coef_[0],\n",
    "                        'intercept': switch_model_den.intercept_[0],\n",
    "                        'X': X_den,\n",
    "                        'y': y\n",
    "                    }\n",
    "        \n",
    "        self.trial_data['weight'] = censor_weights * switch_weights\n",
    "        q99 = np.percentile(self.trial_data['weight'], 99)\n",
    "        self.trial_data['weight'] = self.trial_data['weight'].clip(upper=q99)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def show_weight_models(self):\n",
    "        \"\"\"Display weight model statistics\"\"\"\n",
    "        output = []\n",
    "\n",
    "        if not hasattr(self, 'weight_models') or self.weight_models is None:\n",
    "            return \"No weight models have been calculated yet. Use calculate_weights() first.\"\n",
    "    \n",
    "        output.append(\"Weight Models for Informative Censoring\")\n",
    "        output.append(\"-\" * 40)\n",
    "        \n",
    "        model = self.weight_models['censoring']['numerator']\n",
    "        if model is not None:\n",
    "            output.append(\"\\n[[n]]\")\n",
    "            output.append(\"Model: P(censor_event = 0 | X) for numerator\")\n",
    "            \n",
    "            X = model['X']\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X = X.values\n",
    "            y = model['y']\n",
    "            coef = np.concatenate([[model['intercept']], model['coefficients']])\n",
    "\n",
    "            # Handle 1D arrays\n",
    "            if X.ndim == 1:\n",
    "                X = X.reshape(-1, 1)\n",
    "\n",
    "            if len(coef) != X.shape[1]:\n",
    "                output.append(f\"Warning: Coefficient shape mismatch: {len(coef)} vs {X.shape[1]}\")\n",
    "                # Adjust coef or X as needed\n",
    "                if len(coef) > X.shape[1]:\n",
    "                    coef = coef[:X.shape[1]]\n",
    "                else:\n",
    "                    # Handle if X has more columns than coefficients\n",
    "                    X = X[:, :len(coef)]\n",
    "                \n",
    "            pred = 1 / (1 + np.exp(-X @ coef))\n",
    "            V = np.diag(pred * (1 - pred))\n",
    "\n",
    "            try:\n",
    "                cov = np.linalg.inv(X.T @ V @ X)\n",
    "                se = np.sqrt(np.diag(cov))\n",
    "                \n",
    "                z_stats = coef / se\n",
    "                p_values = 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stats)))\n",
    "\n",
    "                mean_y = np.mean(y)\n",
    "                if mean_y in [0, 1]:\n",
    "                    null_dev = 0\n",
    "                else:\n",
    "                    null_dev = -2 * np.sum(y * np.log(mean_y) + (1 - y) * np.log(1 - mean_y))\n",
    "                \n",
    "                model_dev = -2 * np.sum(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
    "                \n",
    "                terms = ['(Intercept)'] + ['x2']\n",
    "                output.append(\"\\nterm        estimate    std.error  statistic  p.value\")\n",
    "                for term, est, std, z, p in zip(terms, coef, se, z_stats, p_values):\n",
    "                    output.append(f\"{term:10} {est:10.8f} {std:10.8f} {z:10.8f} {p:10.8f}\")\n",
    "                \n",
    "                output.append(f\"\\nnull.deviance: {null_dev:8.4f}\")\n",
    "                output.append(f\"deviance: {model_dev:8.4f}\")\n",
    "                output.append(f\"nobs: {len(y)}\")\n",
    "            except np.linalg.LinAlgError:\n",
    "                output.append(\"Error: Covariance matrix is singular. Cannot compute standard errors.\")\n",
    "    \n",
    "        for prev_treat in [0, 1]:\n",
    "            model = self.weight_models['censoring'][f'denominator_{prev_treat}']\n",
    "            if model is not None:\n",
    "                output.append(f\"\\n[[d{prev_treat}]]\")\n",
    "                output.append(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_treat}) for denominator\")\n",
    "                \n",
    "                X = model['X']\n",
    "                if isinstance(X, pd.DataFrame):\n",
    "                    X = X.values\n",
    "                y = model['y']\n",
    "                if isinstance(y, pd.Series):\n",
    "                    y = y.values\n",
    "                coef = np.concatenate([[model['intercept']], model['coefficients']])\n",
    "                \n",
    "                # Handle 1D arrays\n",
    "                if X.ndim == 1:\n",
    "                    X = X.reshape(-1, 1)\n",
    "                \n",
    "                pred = 1 / (1 + np.exp(-X @ coef))\n",
    "                V = np.diag(pred * (1 - pred))\n",
    "                \n",
    "                try:\n",
    "                    cov = np.linalg.inv(X.T @ V @ X)\n",
    "                    se = np.sqrt(np.diag(cov))\n",
    "                    \n",
    "                    z_stats = coef / se\n",
    "                    p_values = 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stats)))\n",
    "                    \n",
    "                    null_dev = -2 * np.sum(y * np.log(np.mean(y)) + (1-y) * np.log(1-np.mean(y))) if np.mean(y) not in [0, 1] else 0\n",
    "                    model_dev = -2 * np.sum(y * np.log(pred) + (1-y) * np.log(1-pred))\n",
    "                    \n",
    "                    terms = ['(Intercept)', 'x2', 'x1']\n",
    "                    output.append(\"\\nterm        estimate    std.error  statistic  p.value\")\n",
    "                    for term, est, std, z, p in zip(terms, coef, se, z_stats, p_values):\n",
    "                        output.append(f\"{term:10} {est:10.8f} {std:10.8f} {z:10.8f} {p:10.8f}\")\n",
    "                    \n",
    "                    output.append(f\"\\nnull.deviance: {null_dev:8.4f}\")\n",
    "                    output.append(f\"deviance: {model_dev:8.4f}\")\n",
    "                    output.append(f\"nobs: {len(y)}\")\n",
    "                except np.linalg.LinAlgError:\n",
    "                    output.append(\"Error: Covariance matrix is singular. Cannot compute standard errors.\")\n",
    "    \n",
    "        output.append(\"\\nWeight Models for Treatment Switching\")\n",
    "        output.append(\"-------------------------------------\")\n",
    "        \n",
    "        for prev_treat in [0, 1]:\n",
    "            model = self.weight_models['switching'][f'numerator_{prev_treat}']\n",
    "            if model is not None:\n",
    "                output.append(f\"\\n[[n{prev_treat}]]\")\n",
    "                output.append(f\"Model: P(treatment = 1 | previous treatment = {prev_treat}) for numerator\")\n",
    "                \n",
    "                X = model['X']\n",
    "                if isinstance(X, pd.DataFrame):\n",
    "                    X = X.values\n",
    "                y = model['y']\n",
    "                if isinstance(y, pd.Series):\n",
    "                    y = y.values\n",
    "                coef = np.concatenate([[model['intercept']], model['coefficients']])\n",
    "                \n",
    "                # Handle 1D arrays\n",
    "                if X.ndim == 1:\n",
    "                    X = X.reshape(-1, 1)\n",
    "                \n",
    "                pred = 1 / (1 + np.exp(-X @ coef))\n",
    "                V = np.diag(pred * (1 - pred))\n",
    "                \n",
    "                try:\n",
    "                    cov = np.linalg.inv(X.T @ V @ X)\n",
    "                    se = np.sqrt(np.diag(cov))\n",
    "                    \n",
    "                    z_stats = coef / se\n",
    "                    p_values = 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stats)))\n",
    "                    \n",
    "                    null_dev = -2 * np.sum(y * np.log(np.mean(y)) + (1-y) * np.log(1-np.mean(y))) if np.mean(y) not in [0, 1] else 0\n",
    "                    model_dev = -2 * np.sum(y * np.log(pred) + (1-y) * np.log(1-pred))\n",
    "                    \n",
    "                    terms = ['(Intercept)', 'age']\n",
    "                    output.append(\"\\nterm        estimate    std.error  statistic  p.value\")\n",
    "                    for term, est, std, z, p in zip(terms, coef, se, z_stats, p_values):\n",
    "                        output.append(f\"{term:10} {est:10.8f} {std:10.8f} {z:10.8f} {p:10.8f}\")\n",
    "\n",
    "                    output.append(f\"\\nnull.deviance: {null_dev:8.4f}\")\n",
    "                    output.append(f\"deviance: {model_dev:8.4f}\")\n",
    "                    output.append(f\"nobs: {len(y)}\")\n",
    "                except np.linalg.LinAlgError:\n",
    "                    output.append(\"Error: Covariance matrix is singular. Cannot compute standard errors.\")\n",
    "            \n",
    "            model = self.weight_models['switching'][f'denominator_{prev_treat}']\n",
    "            if model is not None:\n",
    "                output.append(f\"\\n[[d{prev_treat}]]\")\n",
    "                output.append(f\"Model: P(treatment = 1 | previous treatment = {prev_treat}) for denominator\")\n",
    "                \n",
    "                X = model['X']\n",
    "                if isinstance(X, pd.DataFrame):\n",
    "                    X = X.values\n",
    "                y = model['y']\n",
    "                if isinstance(y, pd.Series):\n",
    "                    y = y.values\n",
    "                coef = np.concatenate([[model['intercept']], model['coefficients']])\n",
    "                \n",
    "                # Handle 1D arrays\n",
    "                if X.ndim == 1:\n",
    "                    X = X.reshape(-1, 1)\n",
    "                \n",
    "                pred = 1 / (1 + np.exp(-X @ coef))\n",
    "                V = np.diag(pred * (1 - pred))\n",
    "                \n",
    "                try:\n",
    "                    cov = np.linalg.inv(X.T @ V @ X)\n",
    "                    se = np.sqrt(np.diag(cov))\n",
    "                    \n",
    "                    z_stats = coef / se\n",
    "                    p_values = 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stats)))\n",
    "                    \n",
    "                    null_dev = -2 * np.sum(y * np.log(np.mean(y)) + (1-y) * np.log(1-np.mean(y))) if np.mean(y) not in [0, 1] else 0\n",
    "                    model_dev = -2 * np.sum(y * np.log(pred) + (1-y) * np.log(1-pred))\n",
    "                    \n",
    "                    terms = ['(Intercept)', 'age', 'x1', 'x3']\n",
    "                    output.append(\"\\nterm        estimate    std.error  statistic  p.value\")\n",
    "                    for term, est, std, z, p in zip(terms, coef, se, z_stats, p_values):\n",
    "                        output.append(f\"{term:10} {est:10.8f} {std:10.8f} {z:10.8f} {p:10.8f}\")\n",
    "                    \n",
    "                    output.append(f\"\\nnull.deviance: {null_dev:8.4f}\")\n",
    "                    output.append(f\"deviance: {model_dev:8.4f}\")\n",
    "                    output.append(f\"nobs: {len(y)}\")\n",
    "                except np.linalg.LinAlgError:\n",
    "                    output.append(\"Error: Covariance matrix is singular. Cannot compute standard errors.\")\n",
    "        \n",
    "        return \"\\n\".join(output)\n",
    "\n",
    "    def set_expansion_options(self, chunk_size=500):\n",
    "        \"\"\"Set options for expanding trials\"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.expansion_specified = True\n",
    "        return self\n",
    "    \n",
    "    def expand_trials(self):\n",
    "        \"\"\"Expand observational data into sequence of trials\"\"\"\n",
    "        if self.trial_data is None:\n",
    "            raise ValueError(\"Must prepare data first using prepare_data()\")\n",
    "            \n",
    "        expanded_data = []\n",
    "    \n",
    "        time_points = sorted(self.trial_data['period'].unique())\n",
    "        \n",
    "        for t in time_points:\n",
    "            trial_data = self.trial_data[self.trial_data['period'] >= t].copy()\n",
    "            trial_data['trial_time'] = trial_data['period'] - t\n",
    "            trial_data['trial_id'] = t\n",
    "            expanded_data.append(trial_data)\n",
    "        \n",
    "        self.expanded_data = pd.concat(expanded_data, ignore_index=True)\n",
    "        return self\n",
    "    \n",
    "    def load_expanded_data(self, seed=1234, p_control=0.5):\n",
    "        \"\"\"Sample from expanded trials data\"\"\"\n",
    "        if not hasattr(self, 'expanded_data') or self.expanded_data is None:\n",
    "            raise ValueError(\"Must expand trials first using expand_trials()\")\n",
    "            \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        control_size = int(len(self.expanded_data) * p_control)\n",
    "        sampled_indices = np.random.choice(\n",
    "            len(self.expanded_data), \n",
    "            size=control_size, \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        self.sampled_data = self.expanded_data.iloc[sampled_indices].copy()\n",
    "        return self\n",
    "        \n",
    "    def fit_msm_model(self):\n",
    "        \"\"\"Fit the MSM model and store it in self.msm_model\"\"\"\n",
    "        if self.trial_data is None:\n",
    "            raise ValueError(\"Must prepare data first using prepare_data()\")\n",
    "            \n",
    "        X = self.trial_data[['x1', 'x2', 'x3']]\n",
    "        y = self.trial_data['treatment']\n",
    "    \n",
    "        self.msm_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "        self.msm_model.fit(X, y)\n",
    "        self.outcome_model_specified = True\n",
    "        return self\n",
    "\n",
    "    def plot_survival_difference(self):\n",
    "        \"\"\"Plot survival curves for different treatment groups\"\"\"\n",
    "        if self.trial_data is None:\n",
    "            raise ValueError(\"Must prepare data first using prepare_data()\")\n",
    "            \n",
    "        # Check if duration column exists\n",
    "        if 'duration' not in self.trial_data.columns:\n",
    "            raise ValueError(\"The trial_data must contain a 'duration' column for survival analysis\")\n",
    "        \n",
    "        kmf = KaplanMeierFitter()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Plot for each treatment group\n",
    "        for treatment in self.trial_data['treatment'].unique():\n",
    "            mask = self.trial_data['treatment'] == treatment\n",
    "            \n",
    "            # Some datasets use 'event' instead of 'censored' with opposite meaning\n",
    "            if 'event' in self.trial_data.columns:\n",
    "                event_col = 'event'\n",
    "            else:\n",
    "                event_col = 'censored'\n",
    "                \n",
    "            kmf.fit(\n",
    "                durations=self.trial_data.loc[mask, 'duration'], \n",
    "                event_observed=self.trial_data.loc[mask, event_col],\n",
    "                label=f'Treatment {treatment}'\n",
    "            )\n",
    "            kmf.plot()\n",
    "        \n",
    "        plt.title('Survival Curves by Treatment Group')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Survival Probability')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return self\n",
    "\n",
    "def print_model_summary(model, X, y):\n",
    "    \"\"\"Print a summary of the fitted model in R-like format.\"\"\"\n",
    "    if X is None or y is None:\n",
    "        raise ValueError(\"X and y must be defined before calling this function.\")\n",
    "    \n",
    "    # Get coefficients\n",
    "    coef = model.coef_[0]\n",
    "    intercept = model.intercept_[0]\n",
    "    \n",
    "    # Make sure X is numpy array\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.values\n",
    "        \n",
    "    # Calculate predictions\n",
    "    pred_probs = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    X_with_intercept = sm.add_constant(X)\n",
    "    pred = 1 / (1 + np.exp(-X_with_intercept @ np.concatenate(([intercept], coef))))\n",
    "    V = np.diag(pred * (1 - pred))\n",
    "    \n",
    "    # Calculate covariance matrix\n",
    "    try:\n",
    "        cov = np.linalg.inv(X_with_intercept.T @ V @ X_with_intercept)\n",
    "        se = np.sqrt(np.diag(cov))\n",
    "        \n",
    "        # Calculate z-statistics and p-values\n",
    "        z_stats = np.concatenate(([intercept], coef)) / se\n",
    "        p_values = 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stats)))\n",
    "        \n",
    "        # Create a DataFrame for the summary\n",
    "        feature_names = ['(Intercept)']\n",
    "        if hasattr(X, 'columns'):\n",
    "            feature_names.extend(X.columns)\n",
    "        else:\n",
    "            feature_names.extend([f'x{i}' for i in range(1, len(coef) + 1)])\n",
    "            \n",
    "        summary_df = pd.DataFrame({\n",
    "            'term': feature_names[:len(coef) + 1],\n",
    "            'estimate': np.concatenate(([intercept], coef)),\n",
    "            'std.error': se,\n",
    "            'statistic': z_stats,\n",
    "            'p.value': p_values\n",
    "        })\n",
    "        \n",
    "        # Print the summary\n",
    "        print(\"Model Summary:\\n\")\n",
    "        print(summary_df.to_string(index=False, float_format='%.4f'))\n",
    "        \n",
    "        # Calculate null deviance\n",
    "        mean_y = np.mean(y)\n",
    "        if mean_y in [0, 1]:\n",
    "            null_dev = 0\n",
    "        else:\n",
    "            null_dev = -2 * np.sum(y * np.log(mean_y) + (1 - y) * np.log(1 - mean_y))\n",
    "        \n",
    "        # Calculate model deviance\n",
    "        model_dev = -2 * np.sum(y * np.log(pred_probs + 1e-10) + (1 - y) * np.log(1 - pred_probs + 1e-10))\n",
    "        \n",
    "        # Calculate log-likelihood\n",
    "        log_lik = -model_dev / 2\n",
    "        \n",
    "        # Print additional model statistics\n",
    "        print(f\"\\nnull.deviance: {null_dev:.4f}\")\n",
    "        print(f\"deviance: {model_dev:.4f}\")\n",
    "        print(f\"df.null: {len(y) - 1}\")\n",
    "        print(f\"logLik: {log_lik:.4f}\")\n",
    "        print(f\"AIC: {2 * (len(coef) + 1) - 2 * log_lik:.4f}\")\n",
    "        print(f\"nobs: {len(y)}\")\n",
    "        \n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Error: Covariance matrix is singular. Cannot compute standard errors.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculating model summary: {str(e)}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    try:\n",
    "        data = pd.read_csv(\"../data_censored.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Data file not found. Please check the file path.\")\n",
    "        # Create dummy data for demonstration\n",
    "        import numpy as np\n",
    "        \n",
    "        n_patients = 100\n",
    "        n_periods = 5\n",
    "        rows = []\n",
    "        \n",
    "        for i in range(n_patients):\n",
    "            age = np.random.normal(50, 10)\n",
    "            x1 = np.random.normal(0, 1)\n",
    "            x2 = np.random.normal(0, 1)\n",
    "            x3 = np.random.normal(0, 1)\n",
    "            \n",
    "            for p in range(n_periods):\n",
    "                treatment = np.random.binomial(1, 0.5)\n",
    "                censored = np.random.binomial(1, 0.1)\n",
    "                eligible = 1 if p == 0 else np.random.binomial(1, 0.9)\n",
    "                \n",
    "                rows.append({\n",
    "                    'id': i,\n",
    "                    'period': p,\n",
    "                    'age': age,\n",
    "                    'x1': x1,\n",
    "                    'x2': x2,\n",
    "                    'x3': x3,\n",
    "                    'treatment': treatment,\n",
    "                    'censored': censored,\n",
    "                    'eligible': eligible,\n",
    "                    'duration': p + np.random.exponential(2),\n",
    "                    'event': np.random.binomial(1, 0.2)\n",
    "                })\n",
    "                \n",
    "        data = pd.DataFrame(rows)\n",
    "    \n",
    "    # Set display options for pandas\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_rows', 6)\n",
    "    pd.set_option('display.expand_frame_repr', False)\n",
    "    \n",
    "    print(data.head(6))\n",
    "    \n",
    "    try:\n",
    "        # Create and run analysis\n",
    "        trial = TrialEmulation(data)\n",
    "        \n",
    "        # Set weight specifications first\n",
    "        trial.censor_weights_spec = {\n",
    "            'numerator': 'x2',\n",
    "            'denominator': 'x2 + x1',\n",
    "            'pool_models': 'numerator'\n",
    "        }\n",
    "        \n",
    "        trial.switch_weights_spec = {\n",
    "            'numerator': 'age',\n",
    "            'denominator': 'age + x1 + x3'\n",
    "        }\n",
    "        \n",
    "        # Run analysis\n",
    "        (trial.prepare_data()\n",
    "              .calculate_weights()\n",
    "              .set_expansion_options(chunk_size=500)\n",
    "              .expand_trials()\n",
    "              .load_expanded_data(seed=1234, p_control=0.5)\n",
    "              .fit_msm_model())\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nTrial Sequence Object\")\n",
    "        print(f\"Estimand: {trial.estimand}\\n\")\n",
    "        print(f\"Data:\\n - N: {len(trial.trial_data)} observations from {trial.trial_data['id'].nunique()} patients\\n\")\n",
    "        print(trial.trial_data.head(2))\n",
    "        print(\"--\")\n",
    "        print(trial.trial_data.tail(2))\n",
    "        print(trial)\n",
    "        print(trial.show_weight_specs())\n",
    "        print(trial.show_weight_models())\n",
    "        \n",
    "        # Print model summary\n",
    "        print(\"\\nModel Summary:\")\n",
    "        print_model_summary(trial.msm_model, trial.trial_data[['x1', 'x2', 'x3']], trial.trial_data['treatment'])\n",
    "    \n",
    "        # Plot survival difference\n",
    "        trial.plot_survival_difference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9f394-f137-4225-b156-4414ef96e323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
