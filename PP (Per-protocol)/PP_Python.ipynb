{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30754262-b249-4911-94aa-eae5d82a67b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data:\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  censored  eligible\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0         0         1\n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0         0         0\n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0         0         0\n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0         0         0\n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0         0         0\n",
      "5   1       5          1   0 -0.057482   0  0.734203   41  0.500000        0         1         0\n",
      "\n",
      "Trial Sequence Object\n",
      "Estimand: Per-Protocol\n",
      "\n",
      "Data:\n",
      " - N: 191 observations from 62 patients\n",
      "\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  censored  eligible  prev_treatment  weight\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0         0         1             1.0     1.0\n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0         0         0             1.0     1.0\n",
      "--\n",
      "     id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  censored  eligible  prev_treatment  weight\n",
      "717  99       0          1   1 -0.346378   1  0.575268   65  2.500000        0         0         1             1.0     1.0\n",
      "718  99       1          1   0 -1.106481   1  0.575268   66  2.583333        0         0         0             1.0     1.0\n",
      "\n",
      "IPW for informative censoring:\n",
      " - No weight model specified\n",
      "\n",
      "IPW for treatment switch censoring:\n",
      " - No weight model specified\n",
      "\n",
      "Sequence of Trials Data:\n",
      " - Use set_expansion_options() and expand_trials() to construct the sequence of trials dataset.\n",
      "\n",
      "Outcome model:\n",
      " - Model not specified. Use set_outcome_model()\n",
      "\n",
      " - Numerator formula: 1 - censored ~ x2\n",
      " - Denominator formula: 1 - censored ~ x2 + x1\n",
      " - Numerator model is pooled across treatment arms: True\n",
      " - Model fitter type: te_stats_glm_logit\n",
      " - Weight models not fitted. Use calculate_weights()\n",
      "\n",
      "\n",
      " - Numerator formula: treatment ~ age\n",
      " - Denominator formula: treatment ~ age + x1 + x3\n",
      " - Model fitter type: te_stats_glm_logit\n",
      " - Weight models not fitted. Use calculate_weights()\n",
      "\n",
      "Weight Models for Informative Censoring\n",
      "----------------------------------------\n",
      "\n",
      "[[n]]\n",
      "Model: P(censor_event = 0 | X) for numerator\n",
      "\n",
      "term        estimate    std.error  statistic  p.value\n",
      "(Intercept) 13.81551056 73.48444498 0.18800592 0.85087201\n",
      "x2         0.00000000 82.28100358 0.00000000 1.00000000\n",
      "\n",
      "null.deviance:   0.0000\n",
      "deviance:   0.0004\n",
      "nobs: 191\n",
      "\n",
      "Weight Models for Treatment Switching\n",
      "-------------------------------------\n",
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dot product shape mismatch, (191, 3) vs (4,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0s/y3hcxq2x71j_djfnfp03zn140000gn/T/ipykernel_89309/2247716152.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_weight_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_weight_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nModel Summary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m     \u001b[0mprint_model_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'treatment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;31m# Plot survival difference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_survival_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0s/y3hcxq2x71j_djfnfp03zn140000gn/T/ipykernel_89309/2247716152.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;31m# Calculate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;31m# Calculate standard errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;31m# Calculate covariance matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__matmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAnyArrayLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m         \"\"\"\n\u001b[1;32m   1785\u001b[0m         \u001b[0mMatrix\u001b[0m \u001b[0mmultiplication\u001b[0m \u001b[0musing\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \"\"\"\n\u001b[0;32m-> 1787\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1744\u001b[0m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mlvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m             \u001b[0mrvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1749\u001b[0m                     \u001b[0;34mf\"\u001b[0m\u001b[0;34mDot product shape mismatch, \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m vs \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mrvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dot product shape mismatch, (191, 3) vs (4,)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from lifelines import KaplanMeierFitter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "class TrialEmulation:\n",
    "    def __init__(self, data, estimand=\"Per-Protocol\"):\n",
    "        self.data = data.copy()\n",
    "        self.estimand = estimand\n",
    "        self.trial_data = None\n",
    "        self.msm_model = None\n",
    "        self.expanded_data = None\n",
    "        self.censor_weights_specified = False\n",
    "        self.censor_weights_spec = None\n",
    "        self.switch_weights_specified = False\n",
    "        self.switch_weights_spec = None\n",
    "        self.expansion_specified = False\n",
    "        self.outcome_model_specified = False\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Display trial sequence information\"\"\"\n",
    "        output = []\n",
    "        output.append(\"\\nIPW for informative censoring:\")\n",
    "        if self.censor_weights_specified:\n",
    "            output.append(\" - Weights calculated\")\n",
    "        else:\n",
    "            output.append(\" - No weight model specified\")\n",
    "            \n",
    "        output.append(\"\\nIPW for treatment switch censoring:\")\n",
    "        if self.switch_weights_specified:\n",
    "            output.append(\" - Weights calculated\")\n",
    "        else:\n",
    "            output.append(\" - No weight model specified\")\n",
    "            \n",
    "        output.append(\"\\nSequence of Trials Data:\")\n",
    "        if self.expansion_specified:\n",
    "            output.append(\" - Expansion complete\")\n",
    "        else:\n",
    "            output.append(\" - Use set_expansion_options() and expand_trials() to construct the sequence of trials dataset.\")\n",
    "\n",
    "        output.append(\"\\nOutcome model:\")\n",
    "        if self.outcome_model_specified:\n",
    "            output.append(\" - Model fitted\")\n",
    "            if hasattr(self, 'msm_model') and self.msm_model is not None:\n",
    "                output.append(f\" - Family: Binomial\")\n",
    "                output.append(f\" - Link: logit\")\n",
    "                output.append(f\" - Groups: {len(self.trial_data['id'].unique())}\")\n",
    "        else:\n",
    "            output.append(\" - Model not specified. Use set_outcome_model()\")\n",
    "            \n",
    "        return \"\\n\".join(output)\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Filter data according to per-protocol criteria\"\"\"\n",
    "        pp_data = self.data.copy()\n",
    "        pp_data = pp_data.sort_values(['id', 'period'])\n",
    "        \n",
    "        eligible_ids = pp_data[\n",
    "            (pp_data['period'] == 0) & \n",
    "            (pp_data['eligible'] == 1)\n",
    "        ]['id'].unique()\n",
    "        \n",
    "        pp_data = pp_data[pp_data['id'].isin(eligible_ids)]\n",
    "        \n",
    "        pp_data['prev_treatment'] = pp_data.groupby('id')['treatment'].shift(1)\n",
    "        pp_data['treatment_switch'] = (\n",
    "            (pp_data['treatment'] != pp_data['prev_treatment']) & \n",
    "            (pp_data['period'] > 0)\n",
    "        )\n",
    "        \n",
    "        pp_data['cumulative_switch'] = pp_data.groupby('id')['treatment_switch'].cumsum()\n",
    "        pp_data = pp_data[pp_data['cumulative_switch'] == 0]\n",
    "        pp_data = pp_data[pp_data['censored'] == 0]\n",
    "        \n",
    "        pp_data = pp_data.drop(['treatment_switch', 'cumulative_switch'], axis=1)\n",
    "        pp_data['prev_treatment'] = pp_data['prev_treatment'].fillna(pp_data['treatment'])\n",
    "        \n",
    "        self.trial_data = pp_data\n",
    "        return self\n",
    "\n",
    "    def show_weight_specs(self):\n",
    "        \"\"\"Display weight model specifications\"\"\"\n",
    "        output = []\n",
    "        \n",
    "        if self.censor_weights_spec is not None:\n",
    "            output.append(\"\\n - Numerator formula: 1 - censored ~ \" + self.censor_weights_spec['numerator'])\n",
    "            output.append(\" - Denominator formula: 1 - censored ~ \" + self.censor_weights_spec['denominator'])\n",
    "            output.append(f\" - Numerator model is pooled across treatment arms: {self.censor_weights_spec['pool_models'] in ['numerator', 'both']}\")\n",
    "            output.append(\" - Model fitter type: te_stats_glm_logit\")\n",
    "            output.append(\" - Weight models not fitted. Use calculate_weights()\\n\")\n",
    "        else:\n",
    "            output.append(\" - No weight model specified\\n\")\n",
    "\n",
    "        if self.switch_weights_spec is not None:\n",
    "            output.append(\"\\n - Numerator formula: treatment ~ \" + self.switch_weights_spec['numerator'])\n",
    "            output.append(\" - Denominator formula: treatment ~ \" + self.switch_weights_spec['denominator'])\n",
    "            output.append(\" - Model fitter type: te_stats_glm_logit\")\n",
    "            output.append(\" - Weight models not fitted. Use calculate_weights()\\n\")\n",
    "        else:\n",
    "            output.append(\" - No weight model specified\\n\")\n",
    "            \n",
    "        return \"\\n\".join(output)\n",
    "    \n",
    "    def calculate_weights(self):\n",
    "        \"\"\"Calculate IPW for censoring and treatment switching and store model statistics\"\"\"\n",
    "        from scipy import stats\n",
    "        \n",
    "        self.weight_models = {\n",
    "            'censoring': {'numerator': None, 'denominator_0': None, 'denominator_1': None},\n",
    "            'switching': {'numerator_0': None, 'numerator_1': None, \n",
    "                         'denominator_0': None, 'denominator_1': None}\n",
    "        }\n",
    "        \n",
    "        if len(np.unique(self.trial_data['censored'])) == 1:\n",
    "            censor_weights = np.ones(len(self.trial_data))\n",
    "            self.weight_models['censoring']['numerator'] = {\n",
    "                'coefficients': np.array([0.0]),\n",
    "                'intercept': np.log(1e6),\n",
    "                'X': sm.add_constant(self.trial_data[['x2']]),\n",
    "                'y': np.ones(len(self.trial_data))\n",
    "            }\n",
    "        else:\n",
    "            censor_model_num = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "            X_num = sm.add_constant(self.trial_data[['x2']])\n",
    "            y = 1 - self.trial_data['censored']\n",
    "            \n",
    "            censor_model_num.fit(X_num, y)\n",
    "            num_probs = censor_model_num.predict_proba(X_num)[:, 1]\n",
    "            \n",
    "            self.weight_models['censoring']['numerator'] = {\n",
    "                'coefficients': censor_model_num.coef_[0],\n",
    "                'intercept': censor_model_num.intercept_[0],\n",
    "                'X': X_num,\n",
    "                'y': y\n",
    "            }\n",
    "            \n",
    "            censor_weights = np.ones(len(self.trial_data))\n",
    "            \n",
    "            for prev_treat in [0, 1]:\n",
    "                mask = self.trial_data['prev_treatment'] == prev_treat\n",
    "                if sum(mask) > 0:\n",
    "                    X_den = sm.add_constant(self.trial_data.loc[mask, ['x2', 'x1']])\n",
    "                    censor_model_den = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "                    censor_model_den.fit(X_den, y[mask])\n",
    "                    den_probs = censor_model_den.predict_proba(X_den)[:, 1]\n",
    "                    censor_weights[mask] = num_probs[mask] / (den_probs + 1e-8)\n",
    "                    \n",
    "                    self.weight_models['censoring'][f'denominator_{prev_treat}'] = {\n",
    "                        'coefficients': censor_model_den.coef_[0],\n",
    "                        'intercept': censor_model_den.intercept_[0],\n",
    "                        'X': X_den,\n",
    "                        'y': y[mask]\n",
    "                    }\n",
    "        \n",
    "        switch_weights = np.ones(len(self.trial_data))\n",
    "        \n",
    "        for prev_treat in [0, 1]:\n",
    "            mask = self.trial_data['prev_treatment'] == prev_treat\n",
    "            if sum(mask) > 0:\n",
    "                X_num = sm.add_constant(self.trial_data.loc[mask, ['age']])\n",
    "                y = self.trial_data.loc[mask, 'treatment']\n",
    "            \n",
    "                if len(np.unique(y)) > 1:\n",
    "                    switch_model_num = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "                    switch_model_num.fit(X_num, y)\n",
    "                    num_probs = switch_model_num.predict_proba(X_num)[:, 1]\n",
    "                    \n",
    "                    X_den = sm.add_constant(self.trial_data.loc[mask, ['age', 'x1', 'x3']])\n",
    "                    switch_model_den = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "                    switch_model_den.fit(X_den, y)\n",
    "                    den_probs = switch_model_den.predict_proba(X_den)[:, 1]\n",
    "                    \n",
    "                    switch_weights[mask] = num_probs / (den_probs + 1e-8)\n",
    "                    \n",
    "                    self.weight_models['switching'][f'numerator_{prev_treat}'] = {\n",
    "                        'coefficients': switch_model_num.coef_[0],\n",
    "                        'intercept': switch_model_num.intercept_[0],\n",
    "                        'X': X_num,\n",
    "                        'y': y\n",
    "                    }\n",
    "                    \n",
    "                    self.weight_models['switching'][f'denominator_{prev_treat}'] = {\n",
    "                        'coefficients': switch_model_den.coef_[0],\n",
    "                        'intercept': switch_model_den.intercept_[0],\n",
    "                        'X': X_den,\n",
    "                        'y': y\n",
    "                    }\n",
    "        \n",
    "        self.trial_data['weight'] = censor_weights * switch_weights\n",
    "        q99 = np.percentile(self.trial_data['weight'], 99)\n",
    "        self.trial_data['weight'] = self.trial_data['weight'].clip(upper=q99)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def show_weight_models(self):\n",
    "        \"\"\"Display weight model statistics\"\"\"\n",
    "        from scipy import stats\n",
    "        output = []\n",
    "\n",
    "        if not self.weight_models:\n",
    "            return \"No weight models have been calculated yet.\"\n",
    "    \n",
    "        output.append(\"Weight Models for Informative Censoring\")\n",
    "        output.append(\"-\" * 40)\n",
    "        \n",
    "        model = self.weight_models['censoring']['numerator']\n",
    "        if model is not None:\n",
    "            output.append(\"\\n[[n]]\")\n",
    "            output.append(\"Model: P(censor_event = 0 | X) for numerator\")\n",
    "            \n",
    "            X = model['X'].values\n",
    "            y = model['y']\n",
    "            coef = np.concatenate([[model['intercept']], model['coefficients']])\n",
    "\n",
    "            if X.ndim == 1:\n",
    "                X = X.reshape(-1, 1)\n",
    "                \n",
    "            pred = 1 / (1 + np.exp(-X @ coef))\n",
    "            V = np.diag(pred * (1 - pred))\n",
    "\n",
    "            cov = np.linalg.inv(X.T @ V @ X)\n",
    "            se = np.sqrt(np.diag(cov))\n",
    "            \n",
    "            z_stats = coef / se\n",
    "            p_values = 2 * (1 - stats.norm.cdf(np.abs(z_stats)))\n",
    "\n",
    "            null_dev = -2 * sum(y * np.log(y.mean()) + (1-y) * np.log(1-y.mean())) if y.mean() not in [0, 1] else 0\n",
    "            model_dev = -2 * sum(y * np.log(pred) + (1-y) * np.log(1-pred))\n",
    "            \n",
    "            terms = ['(Intercept)', 'x2']\n",
    "            output.append(\"\\nterm        estimate    std.error  statistic  p.value\")\n",
    "            for term, est, std, z, p in zip(terms, coef, se, z_stats, p_values):\n",
    "                output.append(f\"{term:10} {est:10.8f} {std:10.8f} {z:10.8f} {p:10.8f}\")\n",
    "            \n",
    "            output.append(f\"\\nnull.deviance: {null_dev:8.4f}\")\n",
    "            output.append(f\"deviance: {model_dev:8.4f}\")\n",
    "            output.append(f\"nobs: {len(y)}\")\n",
    "    \n",
    "        for prev_treat in [0, 1]:\n",
    "            model = self.weight_models['censoring'][f'denominator_{prev_treat}']\n",
    "            if model is not None:\n",
    "                output.append(f\"\\n[[d{prev_treat}]]\")\n",
    "                output.append(f\"Model: P(censor_event = 0 | X, previous treatment = {prev_treat}) for denominator\")\n",
    "                \n",
    "                X = model['X'].values\n",
    "                y = model['y'].values\n",
    "                coef = np.concatenate([[model['intercept']], model['coefficients']])\n",
    "                \n",
    "                pred = 1 / (1 + np.exp(-X @ coef))\n",
    "                V = np.diag(pred * (1 - pred))\n",
    "                cov = np.linalg.inv(X.T @ V @ X)\n",
    "                se = np.sqrt(np.diag(cov))\n",
    "                \n",
    "                z_stats = coef / se\n",
    "                p_values = 2 * (1 - stats.norm.cdf(np.abs(z_stats)))\n",
    "                \n",
    "                null_dev = -2 * sum(y * np.log(y.mean()) + (1-y) * np.log(1-y.mean())) if y.mean() not in [0, 1] else 0\n",
    "                model_dev = -2 * sum(y * np.log(pred) + (1-y) * np.log(1-pred))\n",
    "                \n",
    "                terms = ['(Intercept)', 'x2', 'x1']\n",
    "                output.append(\"\\nterm        estimate    std.error  statistic  p.value\")\n",
    "                for term, est, std, z, p in zip(terms, coef, se, z_stats, p_values):\n",
    "                    output.append(f\"{term:10} {est:10.8f} {std:10.8f} {z:10.8f} {p:10.8f}\")\n",
    "                \n",
    "                output.append(f\"\\nnull.deviance: {null_dev:8.4f}\")\n",
    "                output.append(f\"deviance: {model_dev:8.4f}\")\n",
    "                output.append(f\"nobs: {len(y)}\")\n",
    "    \n",
    "        output.append(\"\\nWeight Models for Treatment Switching\")\n",
    "        output.append(\"-------------------------------------\")\n",
    "        \n",
    "        for prev_treat in [0, 1]:\n",
    "            model = self.weight_models['switching'][f'numerator_{prev_treat}']\n",
    "            if model is not None:\n",
    "                output.append(f\"\\n[[n{prev_treat}]]\")\n",
    "                output.append(f\"Model: P(treatment = 1 | previous treatment = {prev_treat}) for numerator\")\n",
    "                \n",
    "                X = model['X'].values\n",
    "                y = model['y']\n",
    "                coef = np.concatenate([[model['intercept']], model['coefficients']])\n",
    "                \n",
    "                pred = 1 / (1 + np.exp(-X @ coef))\n",
    "                V = np.diag(pred * (1 - pred))\n",
    "                cov = np.linalg.inv(X.T @ V @ X)\n",
    "                se = np.sqrt(np.diag(cov))\n",
    "                \n",
    "                z_stats = coef / se\n",
    "                p_values = 2 * (1 - stats.norm.cdf(np.abs(z_stats)))\n",
    "                \n",
    "                null_dev = -2 * sum(y * np.log(y.mean()) + (1-y) * np.log(1-y.mean())) if y.mean() not in [0, 1] else 0\n",
    "                model_dev = -2 * sum(y * np.log(pred) + (1-y) * np.log(1-pred))\n",
    "                \n",
    "                terms = ['(Intercept)', 'age']\n",
    "                output.append(\"\\nterm        estimate    std.error  statistic  p.value\")\n",
    "                for term, est, std, z, p in zip(terms, coef, se, z_stats, p_values):\n",
    "                    output.append(f\"{term:10} {est:10.8f} {std:10.8f} {z:10.8f} {p:10.8f}\")\n",
    "\n",
    "                output.append(f\"\\nnull.deviance: {null_dev:8.4f}\")\n",
    "                output.append(f\"deviance: {model_dev:8.4f}\")\n",
    "                output.append(f\"nobs: {len(y)}\")\n",
    "            \n",
    "            model = self.weight_models['switching'][f'denominator_{prev_treat}']\n",
    "            if model is not None:\n",
    "                output.append(f\"\\n[[d{prev_treat}]]\")\n",
    "                output.append(f\"Model: P(treatment = 1 | previous treatment = {prev_treat}) for denominator\")\n",
    "                \n",
    "                X = model['X'].values\n",
    "                y = model['y']\n",
    "                coef = np.concatenate([[model['intercept']], model['coefficients']])\n",
    "                \n",
    "                pred = 1 / (1 + np.exp(-X @ coef))\n",
    "                V = np.diag(pred * (1 - pred))\n",
    "                \n",
    "                try:\n",
    "                    cov = np.linalg.inv(X.T @ V @ X)\n",
    "                    se = np.sqrt(np.diag(cov))\n",
    "                except np.linalg.LinAlgError:\n",
    "                    output.append(\"Error: Covariance matrix is singular. Cannot compute standard errors.\")\n",
    "                    continue\n",
    "                \n",
    "                z_stats = coef / se\n",
    "                p_values = 2 * (1 - stats.norm.cdf(np.abs(z_stats)))\n",
    "                \n",
    "                null_dev = -2 * sum(y * np.log(y.mean()) + (1-y) * np.log(1-y.mean())) if y.mean() not in [0, 1] else 0\n",
    "                model_dev = -2 * sum(y * np.log(pred) + (1-y) * np.log(1-pred))\n",
    "                \n",
    "                terms = ['(Intercept)', 'age', 'x1', 'x3']\n",
    "                output.append(\"\\nterm        estimate    std.error  statistic  p.value\")\n",
    "                for term, est, std, z, p in zip(terms, coef, se, z_stats, p_values):\n",
    "                    output.append(f\"{term:10} {est:10.8f} {std:10.8f} {z:10.8f} {p:10.8f}\")\n",
    "                \n",
    "                output.append(f\"\\nnull.deviance: {null_dev:8.4f}\")\n",
    "                output.append(f\"deviance: {model_dev:8.4f}\")\n",
    "                output.append(f\"nobs: {len(y)}\")\n",
    "        \n",
    "        return \"\\n\".join(output)\n",
    "\n",
    "    def set_expansion_options(self, chunk_size=500):\n",
    "        \"\"\"Set options for expanding trials\"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        return self\n",
    "    \n",
    "    def expand_trials(self):\n",
    "        \"\"\"Expand observational data into sequence of trials\"\"\"\n",
    "        expanded_data = []\n",
    "    \n",
    "        time_points = sorted(self.trial_data['period'].unique())\n",
    "        \n",
    "        for t in time_points:\n",
    "            trial_data = self.trial_data[self.trial_data['period'] >= t].copy()\n",
    "            trial_data['trial_time'] = trial_data['period'] - t\n",
    "            trial_data['trial_id'] = t\n",
    "            expanded_data.append(trial_data)\n",
    "        \n",
    "        self.expanded_data = pd.concat(expanded_data, ignore_index=True)\n",
    "        return self\n",
    "    \n",
    "    def load_expanded_data(self, seed=1234, p_control=0.5):\n",
    "        \"\"\"Sample from expanded trials data\"\"\"\n",
    "        if not hasattr(self, 'expanded_data'):\n",
    "            raise ValueError(\"Must expand trials first using expand_trials()\")\n",
    "            \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        control_size = int(len(self.expanded_data) * p_control)\n",
    "        sampled_indices = np.random.choice(\n",
    "            len(self.expanded_data), \n",
    "            size=control_size, \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        self.sampled_data = self.expanded_data.iloc[sampled_indices].copy()\n",
    "        return self\n",
    "        \n",
    "    def fit_msm_model(self):\n",
    "        \"\"\"Fit the MSM model and store it in self.msm_model\"\"\"\n",
    "        X = self.trial_data[['x1', 'x2', 'x3']]\n",
    "        y = self.trial_data['treatment']\n",
    "    \n",
    "        self.msm_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "        self.msm_model.fit(X, y)\n",
    "\n",
    "    def plot_survival_difference(self):\n",
    "        \"\"\"Plot survival curves for different treatment groups\"\"\"\n",
    "        kmf = KaplanMeierFitter()\n",
    "        \n",
    "        # Assuming 'treatment' is the treatment group and 'duration' is the time until event/censoring\n",
    "        for treatment in self.trial_data['treatment'].unique():\n",
    "            mask = self.trial_data['treatment'] == treatment\n",
    "            kmf.fit(durations=self.trial_data.loc[mask, 'duration'], event_observed=self.trial_data.loc[mask, 'censored'])\n",
    "            kmf.plot(label=f'Treatment {treatment}')\n",
    "        \n",
    "        plt.title('Survival Curves by Treatment Group')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Survival Probability')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def print_model_summary(model, X, y):\n",
    "    \"\"\"Print a summary of the fitted model in R-like format.\"\"\"\n",
    "    if X is None or y is None:\n",
    "        raise ValueError(\"X and y must be defined before calling this function.\")\n",
    "    \n",
    "    # Get coefficients\n",
    "    coef = model.coef_[0]\n",
    "    intercept = model.intercept_[0]\n",
    "    \n",
    "    # Calculate predictions\n",
    "    pred_probs = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    pred = 1 / (1 + np.exp(-X @ np.concatenate(([intercept], coef))))\n",
    "    V = np.diag(pred * (1 - pred))\n",
    "    \n",
    "    # Calculate covariance matrix\n",
    "    try:\n",
    "        cov = np.linalg.inv(X.T @ V @ X)\n",
    "        se = np.sqrt(np.diag(cov))\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Error: Covariance matrix is singular. Cannot compute standard errors.\")\n",
    "        return\n",
    "    \n",
    "    # Calculate z-statistics and p-values\n",
    "    z_stats = np.concatenate(([intercept], coef)) / np.concatenate(([np.sqrt(np.var(y))], se))\n",
    "    p_values = 2 * (1 - stats.norm.cdf(np.abs(z_stats)))\n",
    "    \n",
    "    # Create a DataFrame for the summary\n",
    "    terms = ['(Intercept)'] + [f'x{i}' for i in range(1, len(coef) + 1)]\n",
    "    summary_df = pd.DataFrame({\n",
    "        'term': terms,\n",
    "        'estimate': np.concatenate(([intercept], coef)),\n",
    "        'std.error': np.concatenate(([np.sqrt(np.var(y))], se)),\n",
    "        'statistic': z_stats,\n",
    "        'p.value': p_values\n",
    "    })\n",
    "    \n",
    "    # Print the summary\n",
    "    print(\"Model Summary:\\n\")\n",
    "    print(summary_df.to_string(index=False, float_format='%.2f'))\n",
    "    \n",
    "    # Calculate null deviance\n",
    "    mean_y = y.mean()\n",
    "    if mean_y in [0, 1]:\n",
    "        null_dev = 0\n",
    "    else:\n",
    "        null_dev = -2 * sum(y * np.log(mean_y) + (1 - y) * np.log(1 - mean_y))\n",
    "    \n",
    "    # Calculate model deviance\n",
    "    model_dev = -2 * sum(y * np.log(pred_probs) + (1 - y) * np.log(1 - pred_probs))\n",
    "    \n",
    "    # Print additional model statistics\n",
    "    print(f\"\\n null.deviance: {null_dev:.2f} df.null: {len(y) - 1} logLik: {model.score(X, y):.2f} AIC: {2 * len(coef) - 2 * model.score(X, y):.2f} nobs: {len(y)}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"../data_censored.csv\")\n",
    "    \n",
    "    # Set display options for pandas\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_rows', 6)\n",
    "    pd.set_option('display.expand_frame_repr', False)\n",
    "    \n",
    "    print(\"Initial data:\")\n",
    "    print(data.head(6))\n",
    "    \n",
    "    # Create and run analysis\n",
    "    trial = TrialEmulation(data)\n",
    "    \n",
    "    # Set weight specifications first\n",
    "    trial.censor_weights_spec = {\n",
    "        'numerator': 'x2',\n",
    "        'denominator': 'x2 + x1',\n",
    "        'pool_models': 'numerator'\n",
    "    }\n",
    "    \n",
    "    trial.switch_weights_spec = {\n",
    "        'numerator': 'age',\n",
    "        'denominator': 'age + x1 + x3'\n",
    "    }\n",
    "    \n",
    "    # Run analysis\n",
    "    (trial.prepare_data()\n",
    "          .calculate_weights()\n",
    "          .set_expansion_options(chunk_size=500)\n",
    "          .expand_trials()\n",
    "          .load_expanded_data(seed=1234, p_control=0.5)\n",
    "          .fit_msm_model())\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nTrial Sequence Object\")\n",
    "    print(f\"Estimand: {trial.estimand}\\n\")\n",
    "    print(f\"Data:\\n - N: {len(trial.trial_data)} observations from {trial.trial_data['id'].nunique()} patients\\n\")\n",
    "    print(trial.trial_data.head(2))\n",
    "    print(\"--\")\n",
    "    print(trial.trial_data.tail(2))\n",
    "    print(trial)\n",
    "    print(trial.show_weight_specs())\n",
    "    print(trial.show_weight_models())\n",
    "\n",
    "    print(\"\\nModel Summary:\")\n",
    "    print_model_summary(trial.msm_model, trial.trial_data[['x1', 'x2', 'x3']], trial.trial_data['treatment'])\n",
    "\n",
    "    # Plot survival difference\n",
    "    trial.plot_survival_difference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
